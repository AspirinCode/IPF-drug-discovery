{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from Enrichment import *\n",
    "from collections import Counter\n",
    "import numpy as np; np.random.seed(0)\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the correct working directory\n",
    "if os.path.isdir('M:/'):\n",
    "    os.chdir('M:\\Box\\Jake-Jegga\\IPF Drug Discovery\\Results')\n",
    "elif os.path.isdir('E:/'):\n",
    "    os.chdir('E:/Box Sync/Jake-Jegga/IPF Drug Discovery/Results')\n",
    "else:\n",
    "    os.chdir('/Users/wano3m/Box Sync/Jake-Jegga/IPF Drug Discovery/Results')\n",
    "top_candidates = pd.read_excel('91+nintedabin enrichment connectivity report.xlsx',sheet_name=0,index_col=0)\n",
    "top_candidates.set_index(top_candidates.index + '_' + top_candidates.Cell+'_'+top_candidates.Dose,inplace=True)\n",
    "enrichment_profiles = pd.read_table('91+nintedanib enrichment by dose by cell type report.txt',index_col = 0)\n",
    "enrichment_profiles.set_index(enrichment_profiles.index + '_' + enrichment_profiles.cellline,inplace=True)\n",
    "enrich = SEA('../../../Ontology_Info/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\Dropbox\\Scripts\\Python codes\\IPF drug discovery\\Enrichment.py:94: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  enriched_genes = ref.loc[query,report.index].apply(lambda x: geneid_table.loc[x[x==1].index,'h_symbol'].dropna().unique().tolist(),axis = 0)\n"
     ]
    }
   ],
   "source": [
    "# calculate IPF enrichment\n",
    "ipf_genes = pd.read_table('IPF DEG combinded logFC.gct',skiprows=2,index_col=0)\n",
    "ipf_up = ipf_genes.columns[ipf_genes.iloc[0,:].astype(float)>=0.6].tolist()\n",
    "ipf_dn = ipf_genes.columns[ipf_genes.iloc[0,:].astype(float)<=-0.6].tolist()\n",
    "ipf_enrichment = pd.Series()\n",
    "for gl in [ipf_up,ipf_dn]:\n",
    "#     for lib in ['BP',' ','Pathway','MP']:\n",
    "    for lib in ['CC']:\n",
    "        ref = enrich.dict_g2t[lib]\n",
    "        tmp_pvals = enrich.get_pvalues(gl,ref,19061,gene_type='H_symbol',return_gene_info=True,max_gene_in_lib=1000)[2]\n",
    "        tmp_pvals = tmp_pvals.set_index('Term_name').genelist\n",
    "        ipf_enrichment = ipf_enrichment.append(tmp_pvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidate_enrichment = enrichment_profiles.loc[top_candidates.index].dropna()\n",
    "reg_vector = -1*(candidate_enrichment.reg == 'up') + 1*(candidate_enrichment.reg == 'dn')\n",
    "candidate_enrichment.Raw_p_value = reg_vector*np.log10(candidate_enrichment.Raw_p_value)\n",
    "cmpd_enrichment_matrix = candidate_enrichment.ix[:,:2]\n",
    "cmpd_enrichment_matrix['cmpd'] = [x.split('_')[0] for x in cmpd_enrichment_matrix.index]\n",
    "cmpd_enrichment_matrix = cmpd_enrichment_matrix.groupby(['cmpd','Term_name']).median()\n",
    "cmpd_enrichment_matrix.reset_index(inplace = True)\n",
    "cmpd_enrichment_matrix = cmpd_enrichment_matrix.pivot(index = 'cmpd',columns = 'Term_name',values = 'Raw_p_value').fillna(0)\n",
    "g2t = candidate_enrichment.ix[:,[1,3]]\n",
    "g2t.genelist = g2t.genelist.apply(lambda x: x.split(', '))\n",
    "g2t = g2t.groupby('Term_name').sum()\n",
    "g2t.genelist = g2t.genelist.apply(lambda x: ', '.join((set(x))))\n",
    "g2t.transpose().append(cmpd_enrichment_matrix).to_csv('19 candidate cmpd enrichment matrix.txt',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans,AgglomerativeClustering\n",
    "import sklearn.preprocessing as preprocessing \n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "\n",
    "def t2g_series_parser(t2g):\n",
    "    import pandas as pd\n",
    "    if not isinstance(t2g, pd.Series):\n",
    "        if t2g.shape[1] == 1:\n",
    "            t2g = t2g.ix[:,0]\n",
    "        else:\n",
    "            raise ValueError('Input dataframe must be a pandas Series object!')\n",
    "    if ', ' in t2g.ix[0,0]:\n",
    "        sep = ', '\n",
    "        print('Genelist seems to be stored as a string with separator as \", \".\\nAttempt to parse...')\n",
    "    elif ',' in t2g.ix[0,0]:\n",
    "        sep = ','\n",
    "        print('Genelist seems to be stored as a string with separator as \",\".\\nAttempt to parse...')\n",
    "    elif ' ' in t2g.ix[0,0]:\n",
    "        sep = ' '\n",
    "        print('Genelist seems to be stored as a string with separator as \",\".\\nAttempt to parse...')\n",
    "    split_attempt = t2g.apply(lambda x: x.split(sep))\n",
    "    if ((split_attempt.apply(len) == 1).unique()==[True])[0]:\n",
    "        raise ValueError('Input was not parsed correctly, plsease check!')\n",
    "    else:\n",
    "        print('Parsing is successful!')\n",
    "    # use str.split to split and expand series\n",
    "    t2g_matrix = t2g.str.split(sep,expand=True)\n",
    "    # stack, de-stack, reset_index, and pivot it!\n",
    "    t2g_matrix = t2g_matrix.stack().reset_index()\n",
    "    t2g_matrix['cell_value'] = 1\n",
    "    t2g_matrix = t2g_matrix.pivot(t2g_matrix.columns[0],0,values = 'cell_value').fillna(0)\n",
    "    return t2g_matrix\n",
    "\n",
    "def Find_n_clusters(t2g_matrix,max_clusters = 100):\n",
    "    '''\n",
    "    t2g_matrix is a dataframe of term by genes\n",
    "    This function finds the best K number according to the highest silhouett_average value\n",
    "    '''\n",
    "#     pca = PCA(50)\n",
    "#     t2g_matrix = pca.fit_transform(t2g_matrix)\n",
    "#     min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#     t2g_matrix = min_max_scaler.fit_transform(t2g_matrix)\n",
    "#     t2g_matrix = preprocessing.normalize(t2g_matrix,axis = 0)\n",
    "#     tsne = TSNE(5,perplexity=40,verbose=2)\n",
    "#     t2g_matrix = tsne.fit_transform(t2g_matrix)\n",
    "    t2g_matrix = squareform(pdist(t2g_matrix,metric = 'correlation')) \n",
    "    Ks = range(10,max_clusters)\n",
    "    km = [AgglomerativeClustering(n_clusters=i,affinity='precomputed',linkage='complete') for i in Ks]\n",
    "    #     km = [AgglomerativeClustering(n_clusters=i) for i in Ks]\n",
    "    labels_list = [km[i].fit_predict(t2g_matrix) for i in range(len(km))]\n",
    "    # score_list = [km[i].fit_transform(t2g_matrix).min(axis = 1).sum() for i in range(len(km))]\n",
    "    silhouette_avg_list = [silhouette_score(t2g_matrix, cluster_labels,metric = 'precomputed') for cluster_labels in labels_list]\n",
    "    for i,score in enumerate(silhouette_avg_list):\n",
    "        print('silhouette score for {} clusters: {:.2f}'.format(str(Ks[i]), score))\n",
    "    best_idx = silhouette_avg_list.index(max(silhouette_avg_list))\n",
    "    return Ks[best_idx],labels_list[best_idx]\n",
    "\n",
    "def MEA(t2g_clustered):\n",
    "    MEA_lib = pd.DataFrame()\n",
    "    grouped = t2g_clustered.groupby('cluster')\n",
    "    term2cluster = pd.Series(t2g_clustered.index,index = labels)\n",
    "    gene_counts = grouped.agg('sum')\n",
    "    cluster_size = grouped[t2g_clustered.columns[0]].agg('count')\n",
    "    for cluster in gene_counts.index:\n",
    "        # determine cluster associated genes selection threshold\n",
    "    #     num_terms = cluster_size[cluster]\n",
    "    #     num_iters = range(10000)\n",
    "    #     list_idx = [np.random.randint(0,len(t2g_clustered),size = num_terms) for x in num_iters]\n",
    "    #     permutation_matrix = np.array([t2g_clustered.iloc[x,1:].sum().values for x in list_idx])\n",
    "    #     gene_threshold = np.percentile(permutation_matrix,0.999,axis = 0)\n",
    "\n",
    "        # find gene significantly associated with term cluster\n",
    "        tmp_gene_vector = gene_counts.loc[cluster]\n",
    "        gene_threshold = tmp_gene_vector.mean() + 2*tmp_gene_vector.std()\n",
    "        print('Gene threshold for metacluster {} of size {} is {}'.format(cluster+1,cluster_size.loc[cluster],gene_threshold))\n",
    "        genes = gene_counts.columns[tmp_gene_vector>gene_threshold].tolist()\n",
    "        # reconstruct tmp_gene_vector\n",
    "        cluster_gene_vector = pd.Series(0,index = t2g_clustered.columns[1:])\n",
    "        cluster_gene_vector[genes] = 1\n",
    "\n",
    "        cluster_terms = term2cluster[cluster].values\n",
    "        cluster_term_vector = t2g_clustered.ix[cluster_terms,1:]\n",
    "        cors = cluster_term_vector.corrwith(cluster_gene_vector,axis = 1)\n",
    "    #     cors = cluster_term_vector.corrwith(cluster_term_vector.mean(axis = 0),axis = 1)\n",
    "        # calculating correlation only on selected genes\n",
    "        cors = cluster_term_vector[genes].corrwith(cluster_term_vector[genes].mean(axis = 0),axis = 1)\n",
    "        best_5_terms = cors.sort_values(ascending = False).index[:5].tolist()\n",
    "        MEA_lib.ix['MEA_term_' + str(cluster+1),'genes'] = ','.join(sorted(genes))\n",
    "        MEA_lib.ix['MEA_term_' + str(cluster+1),'best_terms'] = ','.join(sorted(best_5_terms))\n",
    "        MEA_lib.ix['MEA_term_' + str(cluster+1),'term_size'] = len(genes)\n",
    "    return MEA_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2g_matrix = t2g_series_parser(ipf_enrichment)\n",
    "if t2g_matrix.columns[0] in enrich.geneid_table.index:\n",
    "    t2g_matrix = t2g_matrix.transpose().merge(pd.DataFrame(enrich.geneid_table.ix[:,1]),left_index = True, right_index = True, how='left')\n",
    "    t2g_matrix = t2g_matrix.drop_duplicates('h_entrez_id')\n",
    "    t2g_matrix = t2g_matrix.set_index('h_entrez_id').transpose()\n",
    "_, labels = Find_n_clusters(t2g_matrix,max_clusters=26)\n",
    "t2g_matrix.insert(0,'cluster',labels)\n",
    "mea_lib = MEA(t2g_matrix)\n",
    "geneid_table = enrich.geneid_table\n",
    "mea_lib_t2g = t2g_series_parser(mea_lib.genes).transpose()\n",
    "# mea_lib_t2g = mea_lib_t2g.merge(pd.DataFrame(geneid_table.h_entrez_id),left_index=True,right_index=True,how='inner')\n",
    "# mea_lib_t2g = mea_lib_t2g.drop_duplicates(subset='h_entrez_id').set_index('h_entrez_id')\n",
    "\n",
    "# # Improved version using grouping\n",
    "# # load Lincs data\n",
    "# lincs_up_gl = pd.read_table('../../../Lincs_data/Lincs_Cmpd_Up_500_Genes.txt',index_col = 0)\n",
    "# lincs_dn_gl = pd.read_table('../../../Lincs_data/Lincs_Cmpd_Dn_500_Genes.txt',index_col = 0)\n",
    "# lincs_up_gl['reg'] = 'up'\n",
    "# lincs_dn_gl['reg'] = 'dn'\n",
    "# lincs_gl = lincs_up_gl.append(lincs_dn_gl)\n",
    "# del lincs_up_gl\n",
    "# del lincs_dn_gl\n",
    "# lincs_meta_data = pd.read_table('../../../Lincs_data/Lincs_P1+P2_sig_info.txt',index_col = 0)\n",
    "# all_lincs_genes = pd.read_table('../../../Lincs_data/GSE92742_Broad_LINCS_gene_info.txt').ix[:,0].tolist()\n",
    "\n",
    "# # Running enrichment using the mea libs\n",
    "# lincs_gl['cmpd_cell_dose'] = lincs_gl.pert_iname + '_' + lincs_gl.cell_id + '_' + lincs_gl.pert_idose\n",
    "# lincs_gl.set_index('cmpd_cell_dose',inplace=True)\n",
    "# top_candidates_gl = lincs_gl.loc[top_candidates.index]\n",
    "# sea_query_gl = pd.DataFrame()\n",
    "# for cmpd in top_candidates_gl.index:\n",
    "#     cmpd_df = top_candidates_gl.loc[cmpd]\n",
    "#     threshold = 0.25*cmpd_df.shape[0]\n",
    "#     cmpd_df.Top_genes = cmpd_df.Top_genes.apply(lambda x: x.split(','))\n",
    "#     all_genes = list(set(cmpd_df.Top_genes.sum()))\n",
    "#     gene_counts_up = pd.Series(Counter(cmpd_df[cmpd_df.reg == 'up'].Top_genes.sum()))\n",
    "#     gene_counts_dn = pd.Series(Counter(cmpd_df[cmpd_df.reg == 'dn'].Top_genes.sum()))\n",
    "#     gene_counts = pd.DataFrame(0,index = all_genes,columns=['up','dn'])\n",
    "#     gene_counts.ix[gene_counts_up.index,0] = gene_counts_up\n",
    "#     gene_counts.ix[gene_counts_dn.index,1] = gene_counts_dn\n",
    "#     gene_counts['t'] = gene_counts.up-gene_counts.dn\n",
    "#     up_reg_genes = gene_counts.index[gene_counts.t>threshold].tolist()\n",
    "#     dn_reg_genes = gene_counts.index[gene_counts.t<-threshold].tolist()\n",
    "#     sea_query_gl.ix[cmpd.split('_')[0],'up'] = ','.join(up_reg_genes)\n",
    "#     sea_query_gl.ix[cmpd.split('_')[0],'up_size'] = len(up_reg_genes)\n",
    "#     sea_query_gl.ix[cmpd.split('_')[0],'dn'] = ','.join(dn_reg_genes)\n",
    "#     sea_query_gl.ix[cmpd.split('_')[0],'dn_size'] = len(dn_reg_genes)\n",
    "    \n",
    "# mea_cmpd_sea = pd.DataFrame()\n",
    "# for cmpd in sea_query_gl.index:\n",
    "#     for reg in ['up','dn']:\n",
    "#         gl = sea_query_gl.ix[cmpd,reg].split(',')\n",
    "#         N = len(gl)\n",
    "#         if [x for x in gl if x in mea_lib_t2g.index] == []:\n",
    "#             print('Genelist has no common genes with ref!')\n",
    "#             continue\n",
    "#         tmp_pvals = enrich.get_pvalues(gl,mea_lib_t2g,19055,return_gene_info=True)[2]\n",
    "#         log_tmp_pvals = pd.DataFrame((-1*(reg=='up')+(reg=='dn')) * np.log10(tmp_pvals.Raw_p_value))\n",
    "#         log_tmp_pvals['cmpd'] = cmpd\n",
    "#         log_tmp_pvals['genelist'] = tmp_pvals.genelist\n",
    "#         mea_cmpd_sea=mea_cmpd_sea.append(log_tmp_pvals)\n",
    "# # Re-enrich IPF genes against mea_lib        \n",
    "# for gl, reg in zip([ipf_up,ipf_dn],['up','dn']):\n",
    "#     tmp_pvals = enrich.get_pvalues(gl,mea_lib_t2g,19055, gene_type='H_symbol', return_gene_info=True)[2]\n",
    "#     log_tmp_pvals = pd.DataFrame((-1*(reg=='up')+(reg=='dn')) * np.log10(tmp_pvals.Raw_p_value))\n",
    "#     log_tmp_pvals['cmpd'] = 'IPF'\n",
    "#     log_tmp_pvals['genelist'] = tmp_pvals.genelist\n",
    "#     mea_cmpd_sea=mea_cmpd_sea.append(log_tmp_pvals)\n",
    "    \n",
    "# mea_cmpd_sea['abs'] = mea_cmpd_sea.Raw_p_value.abs()\n",
    "# mea_cmpd_sea['term'] = mea_cmpd_sea.index\n",
    "# mea_cmpd_sea = mea_cmpd_sea.sort_values(['cmpd','term','abs'],ascending=[True,True,False])\n",
    "# mea_cmpd_sea = mea_cmpd_sea.groupby(['cmpd','term']).first()\n",
    "\n",
    "# mea_cmpd_sea_matrix = mea_cmpd_sea.reset_index().ix[:,:3]\n",
    "# mea_cmpd_sea_matrix = mea_cmpd_sea_matrix.pivot('cmpd','term','Raw_p_value').fillna(0).transpose()\n",
    "# mea_cmpd_sea_matrix = mea_lib.merge(mea_cmpd_sea_matrix,left_index=True,right_index=True,how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_candidate_enrichment = pd.read_table('19 candidate cmpd enrichment matrix.txt',index_col=0)\n",
    "cm_terms = [x for x in t2g_matrix.index if x in top_candidate_enrichment.columns]\n",
    "top_candidate_enrichment = top_candidate_enrichment[cm_terms]\n",
    "# ipf_pvals = pd.Series()\n",
    "# for gl,reg in zip([ipf_up,ipf_dn],[-1,1]):\n",
    "#     for lib in ['BP','Pathway','MP']:\n",
    "#         ref = enrich.dict_g2t[lib]\n",
    "#         tmp_pvals = enrich.get_pvalues(gl,ref,19055,gene_type='H_symbol',return_gene_info=True,max_gene_in_lib=1000)[2]\n",
    "#         tmp_pvals = tmp_pvals.set_index('Term_name').Raw_p_value\n",
    "#         tmp_pvals = reg*np.log10(tmp_pvals)\n",
    "#         ipf_pvals = ipf_pvals.append(tmp_pvals)\n",
    "# ipf_pvals = pd.DataFrame(ipf_pvals)\n",
    "# ipf_pvals['term'] = ipf_pvals.index\n",
    "# ipf_pvals = ipf_pvals.groupby('term').mean()\n",
    "top_candidate_enrichment = top_candidate_enrichment.transpose()\n",
    "top_candidate_enrichment.insert(0,'IPF_pval',ipf_pvals.loc[top_candidate_enrichment.index].values)\n",
    "top_candidate_enrichment.insert(0,'cluster',t2g_matrix.ix[top_candidate_enrichment.index,0])\n",
    "top_candidate_enrichment.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantile(apply_df):\n",
    "    if apply_df.median()>=0:\n",
    "        return apply_df.quantile(0.75)\n",
    "    else:\n",
    "        return apply_df.quantile(0.25)\n",
    "    \n",
    "top_candidate_enrichment = top_candidate_enrichment.drop('genelist',axis= 1)\n",
    "top_candidate_enrichment.cluster = ['MEA_term_' + str(x+1) for x in top_candidate_enrichment.cluster]\n",
    "top_candidate_enrichment.ix[:,1:] = top_candidate_enrichment.ix[:,1:].astype(float)\n",
    "top_candidate_enrichment = top_candidate_enrichment.groupby('cluster')\n",
    "top_candidate_enrichment = top_candidate_enrichment.agg(lambda x: get_quantile(x))\n",
    "top_candidate_enrichment = mea_lib.merge(top_candidate_enrichment,left_index=True,right_index=True)\n",
    "top_candidate_enrichment.to_clipboard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gl = enrich.geneid_table.ix[gl,'h_entrez_id'].dropna().unique().tolist()\n",
    "ref.reindex(gl).sum().loc['GO:0031226']\n",
    "ref.sum().loc['GO:0031226']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl = ipf_dn\n",
    "gl = enrich.geneid_table.ix[gl,'h_entrez_id'].dropna().unique().tolist()\n",
    "query = gl\n",
    "M=19061\n",
    "n = ref.sum().values\n",
    "N = len(query)\n",
    "X = ref.ix[query].fillna(0).sum()-1\n",
    "M = np.repeat(M,ref.shape[1])\n",
    "N = np.repeat(N,ref.shape[1])\n",
    "pval = hypergeom.sf(X,M,n,N)\n",
    "fdr = mt(pval,method='fdr_bh')[1]        \n",
    "report = pd.DataFrame(fdr,index = ref.columns, columns = ['FDR_adjusted_pvalue'])\n",
    "report['Raw_p_value'] = pval\n",
    "report = report[report.FDR_adjusted_pvalue<=0.05]\n",
    "report['Term_name'] = enrich.termid2termname.ix[report.index,0]\n",
    "report.sort_values('FDR_adjusted_pvalue',inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
